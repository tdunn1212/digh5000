# Week Two Notes
*Page to-do: including the formatting of my notes in markdown, needs manual update* 
## Pre-Class Work
### Open Science in Archeology
- Publications are all that is visible of the research process in archeology and even at that, most of them are locked behind scholarly institutions
- This directly conflicts with "open science" and trends in academic development which prioritize data ownership, transparency, and public involvement
- Open Science: five themes (infrastructure, the public, measurement, democracy, and pragmatics) to create a more equitable and open model of research and knowledge
	-  Defines the origins of modern science and imagines the future of science
- This can be discussed for archeology across three elements: open access, open data, and open methods

#### Open Access: permanent online access to full texts without charge
- Gold Open Access: authors paying a fee for publication, expensive
	- effects marginalized groups and early-career researchers where fees are not covered
- Green Open Access: authors pre-publish their work ahead of journal publication for open access
- Open access works are more often cited and discussed by the media
- Use by nonacademic communities also helps

#### Open Data: open access to datasets
- Accessing data behind a paywall is often pricey 
- Many sciences see this as outdated and now require studies to pool data in open repositories 
- It is important for researchers to be critical about which private and public data they use
- Open data isn't always good due to privacy concerns

#### Open Methods: open methods of data collection, analysis, and visualization for the public to inspect and use
- Includes empirical methods (e.g. chemical samples) and computational/statistical methods (e.g. taking raw data and producing models and visualizations)
- Helps reproducibility of research and holds researchers accountable
- For archaeology: use transparent softwares (e.g. python or R VS Excel bad), version histories in Git  + Google Docs, and open source methods on reliable platforms

#### How is this relevant?
- It advances research and disseminates knowledge
- It improves practices and promotes ethics
  -  Allows colleagues to build on other's work
- Allows for feedback
- Creates bonds and communities in a worldwide group of researchers
  - Standardized methods allow for more sharing and communities
	- Removing financial barriers makes research more equitable and accessible to all kinds of learners
- How to make reproducible research:
  - Make open-scripted data analysis workflows, allowing others to evaluate your work
  - Encouraging and requesting others' data and code
  - Using data management plans in all research designs
  - Teaching students to work openly
  - Archiving papers in open repositories
  - Archiving data and code in trusted repositories and linking them in papers
- Taking whatever steps you can and encouraging others promotes aggregate change

### Do DHists need to Understand Algorithms?
#### Algorithms and Transforms
- Fetishizing algorithms “pollute our ability to accurately describe the world we live in”
- Algorithms have become buzzwords used to market multiple complex systems
  - This distorts and mysticises algorithms, neglecting human agency
- Researchers need to better understand and adapt to algorithms rather than blindly hate them 
- Algorithm: a set of specifiable steps that produce an output, central to computer science
- Transformations: reconfigurations that an algorithm might affect
  - Algorithms create transformation
  - Transformations' goals are independent of the algorithms that create them (e.g. sorting)

#### The Fourier Transform and Literary Time
- Transformations can enrich people's experiences of text and their descriptions
- The algorithm sorts the general positive/negative mood of literary texts over the plot of the novel
- “The purpose of the Fourier transform is to represent cyclical events as frequencies by breaking complex signals into their component parts.”
- Representing the novel on cartesian plots makes them seem infinite, on radial plots, they seem cyclical
- Positive and negative is also subjective and contains nuance
  - Vonnegut better sees it as fortune/misfortune
- As digital humanists, we ought to dispel myths of algorithmic domination, not foster them

### Data Feminism 4: What Gets Counted Counts

#### Principle: Rethink Binaries and Hierarchies
- Data feminism requires us to challenge the gender binary, along with other systems of counting and classification that perpetuate oppression
- Our data is collected by many corporations in binary ways, ostracizing gender minorities
  - This ostracizes non binary people from even making bank accounts
  - The data we collect is the basis for policies and resources, this makes non-binary genders invisible
- Facebook allows users to self-identify their gender, but still uses a binary model to share with advertisers
- The gender binary is a conceptual classification system that is socially constructed
- Machine learning techniques that aggregate information further double down on these classifications
- We shouldn't neglect all classifications, but we should think critically about how they are formed and how they change us
- Paradox of Exposure: the double bind for minorities that places those who stand to gain from being counted in the most danger from that same classifying act

#### Questioning Classification Systems
- The Matrix of Domination: a system where race, gender, class, and other factors intersect to limit and promote opportunities for people based on their identities
	- e.g. the TSA scanners allow normative bodies to pass through with ease and penalizes nonnormative bodies
- Gender performances still reinforce the concepts of gender
- To better collect data for different genders, collect gender in more than binary categories and disaggregate the data throughout the analysis process
  - There are some circumstances where counting gender is more crucial than others

#### Rethinking Binaries in Data Visualization
- Considering political implications of data collection should not just be limited to gender, it should also include race
- Conforming to perceived data stereotypes in visualization doubles down on bias
- There is no biological measure for binary categorization without variation
- Just because visualizations should reduce complexity, doesn't mean there isn't room for them to push against intuition and contain nuance

#### Refusing Data, Recovering Data
- Being counted and represented in data isn't always good, especially when designers do not have understanding of who they're representing
- Consent is crucial in data collection
- “Information studies scholars Oliver Haimson and Anna Lauren Hoffman have studied the effects of the company’s “real name” policy, under which the platform determines each user’s registered name to be either “real” and authentic or simply “fake.”” (“4. ˝What Gets Counted Counts˛”, p. 21)

#### Counting as Healing, Counting as Accountability
- “But when a community is counting for itself, about itself, there is the potential that data collection can be not only be empowering but also healing” (“4. ˝What Gets Counted Counts˛”, p. 24)
- Quantitative data itself can't contain the full breadth of one person, but allowing for more diverse categorization helps preventing furthering oppression and reduction
- Rethink binaries and hierarchies

### Data Feminism 6: Numbers Don't Speak
#### Principle: Consider Context
Data is not neutral or objective, they are products of unequal social relations, and context is essential for conducting accurate, ethical analysis
	- Data collection APIs built on social media data are targeted and often unreliable in how they source data automatically

#### Situating Data on the World Wide Web
- A large amount of data available online comes without context and metadata on its sources and meaning
- Knowledge Infrastructure: the ecology of people, practices, technologies, institutions, material objects, and relationships data is situated in
  - It is our job to understand data along with its knowledge infrastructure
- The Open Data movement has been rapidly expanded to allow for progress and government accountability, but most open data lacks crucial context that makes it accessible to the general public and journalists
- Zombie Data: datasets published without any clear purpose or use case in mind
  - Chris Anderson believed this wasn't a bad thing and that "the numbers would speak for themselves" and that this would mitigate statistical interference and the need to model samples based on population
- Correlation and Causation in data feeds into sexist and racist pattern, confirming biases
  - Sexual assault statistics are seldom representative of the problem, due to stigmas of victims speaking up, and institutions not wanting to be accountable for the high rate of crimes
- There are imbalances of power in the data world that means we cannot allow data to "speak for itself" and without context
  - Letting data speak for itself tells stories that are false and confirm existing power dynamics
		- For example, letting current sexual assault data speak for itself encourages institutions to underreport data and ignores victims

#### Raw Data, Cooked Data
- Raw data is an oxymoron, since it doesn’t involve raw input
	- The input in which data is reported is constructed, and so is the data
- Data creatives strive to creatively mine and work across diverse datasets to tell contextual stories and make connections
- “Instead of taking data at face value and looking toward future insights, data scientists can first interrogate the context, limitations, and validity of the data under use.”
  - Feminists should examine the context that produces raw data
	- Social media data can't provide a good behavioural sample, e.g. Reddit is primarily male, so it has more male comments than female
- To encourage more creative and contextual use of data and understandings of its structural biases, we need to integrate more theory and understanding of context into our data storytelling
  - “Refusing to acknowledge context is a power play to avoid power. It’s a way to assert authoritativeness and mastery without being required to address the complexity of what the data actually represent:”
- Contextual Analysis of Social media: using deep listening and education to help data collectors mitigate their bias and find meanings of social media posts in dialects and slang
- This method helps pay attention to subjugated knowledges: forms of knowledge that are pushed out of mainstream and the conservations they encourage
- It is also important for data analysts to know and exist within the communities they are surveying and telling stories about

#### Communicating Context
- It is just as crucial to ensure that context is communicated in the final stages of data storytelling as the earlier stages
- Journalism's focus on objectivity often discourages discussion of racism and prejudice so that it can not "pick a side"
  - Racism is not something for readers to decide, it exists matter of fact
- Journalism letting data speak for itself leads to numbers being misinterpreted and losing the results of the study
  - Naming racism and sexism when it is present in a study should be required for data communications 
- “This counsel—to name racism, sexism, or other forces of oppression when they are clearly present in the numbers—particularly applies to designers and data scientists from the dominant group with respect to the issue at hand.”
  - White, straight, male, etc. data communicators need to ensure their communications do not perpetuate power systems
  - It is also important to not create narratives of deficiency in POC, by using data to frame them as passive victims 

#### Restoring Context
- It always involves time and consideration to restore context to data stories
- Write a data biography about your dataset prior to working with it:
  - Where did it come from?
  - Who collected it?
  - When?
  - How was it collected?
  - Why was it collected?
- Microsoft have also encouraged datasheets for datasets, 3-5 page documents that discuss the origins, shortcomings, maintenance, and legal considerations of datasets
- Data user guides are documents that provide "narrative portraits" of datasets
  - “They describe, among other things, the purpose and application of the data; the history, format, and standards; the organizational context; other analyses and stories that have used the dataset; and the limitations and ethical implications of the dataset”
- All these efforts are needed in combination with a balance of qualitative and quantitative data, to fully contextualize stories
  - Marginalized stories cannot be fully told by quantitative statistics
- Data intermediaries like librarians, journalists, nonprofits, educators, and other public sector workers also advocate for the quality of data
- Not only do numbers not speak for themselves, we must prevent them from doing so
  - We do this by considering context, which encourages reflection on data collection and communication, and the social dynamics that relate to the data

### Sources of Harm throughout ML Life Cycle
#### General Notes
- ML algorithms take data from existing sources and use it to generate unseen data 
- Issues with these algorithms can arise during data collection, model development, and deployment processes
- Branding data as biased deflects responsibility from researchers and creators
- “Machine learning is a type of statistical inference that learns, from existing data, a function that can be generalized to new, unseen data.” (Suresh and Guttag, 2021, p. 2)
- Models are built with training data, tested with test data, and evaluated with validation data
- Performance metrics and benchmark datasets in the evaluation stages may also be skewed by creator bias
- “Aggregation bias can lead to a model that is not optimal for any group, or a model that is fit to the dominant population (e.g., if there is also representation bias).” (Suresh and Guttag, 2021, p. 5)

##### Thoughts based on Data Feminism
- Training algorithms based on current models of social power leads to algorithms which reflect those power systems e.g. medical models trained on cis male bodies, photo software based on white faces, LLMs that get their information from general internet trending towards those power systems 
- Even if data is biased, blaming data deflects the responsibility you have as a creator
- The growing prevalence of ML means it becomes more and more important to embed context and diverse data in its development process 
- ML data is often collected based on a target population, which is much less likelier to be POC, women, etc.
- “Recognizing historical bias, for example, requires a retrospective understanding of how structural oppression and discrimination has manifested in a particular domain over time.” (Suresh and Guttag, 2021, p. 6)
  - If researchers are coming from privileged backgrounds, they are likelier to lack awareness of structural oppression

## Seminar

### Data Feminism, what are your connections?
- Currently im in a social robotics class, the people involved in these studies, the people who train these robots
- In the past, I've worked with a lot of datasets, CTAG data and combing through that VS experiences in the community
  - Making the dataset and paraphrasing, who were the respondents and what did they have to say
- Digital Colonialism - Ali
  - Imaginative AI book?
- Reflection on data as you use it 
- Metadata: data that describes data
- Paradata: how we describe the process of data collection, metadata, and the decisions we make 

### What Does Humanities Data look like and how can we create data from our research?
- "Thing Theory" In archeology, assemblage theory (Germanic root of thing, treats objects with agency), finding context and relationship between things from the same period, treating these objects with agency in their locations and purposes
- Text encoding: distinguishing the idea and core of text, what is its semantic content
  - Markup language example, data and documents are in hierarchies, that changes how we read them
  - XML creates your own schema and hierarchy for your list
- Using Voyant-Tools and OCR docs to discuss trends
- What kinds of research questions can we generate?

### Research activity questions
- Canada and tourism, treating Canada as wilderness in advertising and how that feeds into colonial conceptions of Terra Nullius
- How does tourism narratives contribute to viewing Canada as this previously uninhabited wilderness

### How do we make our research more transparent?
- In research contexts and reproducibility, we need to use open and transparent tools like Python and R that doesn't abstract the data cleaning process
- This also makes your research more accessible to yourself in the future
- Open lab notes have potential, but are dangerous, as it leaves you susceptible to exposing your process to bad faith actors, LLMs
- Having notes for yourself gives you the opportunity to share them as needed and maintaining an archive for yourself
  - A txt file is universal and future-proof
  - Sublime or Obsidian
  - GitHub, Static Site Generators, turn it into a website w GitHub.io by going to the settings and "Pages", index.md pages are automatically the home page
- Set up a repository and put notes so far into it, do the pages stuff
